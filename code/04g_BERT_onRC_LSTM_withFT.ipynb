{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cbcb322d3ac9442391d823e19dfc69f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffa651b1ab2d459dbbcd87642e40d9a1","IPY_MODEL_6b823a70104d4a05ae896180be1ecec5","IPY_MODEL_5a44d112e0b64954af40cdd54490fe56"],"layout":"IPY_MODEL_5298d2abcf3145cd97b6fa11db0b1fdb"}},"ffa651b1ab2d459dbbcd87642e40d9a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16a1a4cf7573468fb83f9ff6bf31b4a0","placeholder":"​","style":"IPY_MODEL_39c57964fc93457f889f9cee04512fef","value":"Map: 100%"}},"6b823a70104d4a05ae896180be1ecec5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24e500643f864fc9a9097e462d027987","max":2058,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7543df20c5674102b6d54887931ee237","value":2058}},"5a44d112e0b64954af40cdd54490fe56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8527295917704cd6be470a788ecd600e","placeholder":"​","style":"IPY_MODEL_b684fc4c32a44f1cb3f51d6a6211a658","value":" 2058/2058 [00:01&lt;00:00, 1819.59 examples/s]"}},"5298d2abcf3145cd97b6fa11db0b1fdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16a1a4cf7573468fb83f9ff6bf31b4a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39c57964fc93457f889f9cee04512fef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24e500643f864fc9a9097e462d027987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7543df20c5674102b6d54887931ee237":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8527295917704cd6be470a788ecd600e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b684fc4c32a44f1cb3f51d6a6211a658":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a0f137069244b8eadae6d71e2e611bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7452c440c0ed4f00885ef525f1a5fa38","IPY_MODEL_c9b618c5eb7048718e121b77e549f11a","IPY_MODEL_dd4f7c8e50354fe091c1528d8253cbed"],"layout":"IPY_MODEL_a7f6d334746744c5a488fbc8c943664f"}},"7452c440c0ed4f00885ef525f1a5fa38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58836e57c454442185ab99cf949245cf","placeholder":"​","style":"IPY_MODEL_2e730349d54a4de0afd590fa4861acc4","value":"Map: 100%"}},"c9b618c5eb7048718e121b77e549f11a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_759f30cd97fe4e5895b7317d1bed090d","max":441,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1de88949d8134dff899257ee12833ce2","value":441}},"dd4f7c8e50354fe091c1528d8253cbed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c786831ca79d414998dd3e41388ee765","placeholder":"​","style":"IPY_MODEL_d6e4863a49cd4f788558e904433128bb","value":" 441/441 [00:00&lt;00:00, 1744.47 examples/s]"}},"a7f6d334746744c5a488fbc8c943664f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58836e57c454442185ab99cf949245cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e730349d54a4de0afd590fa4861acc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"759f30cd97fe4e5895b7317d1bed090d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1de88949d8134dff899257ee12833ce2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c786831ca79d414998dd3e41388ee765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e4863a49cd4f788558e904433128bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffef0c4258cd49dc9f2ee89068b91626":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80bcb22e490f4254a78abd92671cbfd1","IPY_MODEL_156f0bf56cba44d28b8f69e27e929e16","IPY_MODEL_fa939afabea5410587828d4bbe6869c6"],"layout":"IPY_MODEL_5dd553c843474e0eb4fcf4284746c527"}},"80bcb22e490f4254a78abd92671cbfd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d45b25c2131b45658c367e071d282583","placeholder":"​","style":"IPY_MODEL_71718265694841049afad204d993f668","value":"Map: 100%"}},"156f0bf56cba44d28b8f69e27e929e16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ae4f33de90049daa36972ea1d392ff4","max":441,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d90b6a32bf44067a024752a3dd08bf3","value":441}},"fa939afabea5410587828d4bbe6869c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b7c82f2f53944609c642d901c9686b6","placeholder":"​","style":"IPY_MODEL_7280e075b86e4e5ba7499355c9306df9","value":" 441/441 [00:00&lt;00:00, 2750.20 examples/s]"}},"5dd553c843474e0eb4fcf4284746c527":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d45b25c2131b45658c367e071d282583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71718265694841049afad204d993f668":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ae4f33de90049daa36972ea1d392ff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d90b6a32bf44067a024752a3dd08bf3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b7c82f2f53944609c642d901c9686b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7280e075b86e4e5ba7499355c9306df9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb96595386d24ff8a666edd26fce2657":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ca3ebe8b9a146929a7f060dde3ac69a","IPY_MODEL_03ba6fa0421f4d43a0e92daba919c42d","IPY_MODEL_8db91486c8344465ae8aff9a403a4d3d"],"layout":"IPY_MODEL_e04e8604244e43c3aea61a804f0bfaf9"}},"4ca3ebe8b9a146929a7f060dde3ac69a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edc75a93d1a64ecd80413f473be172e1","placeholder":"​","style":"IPY_MODEL_a0df3808ae44417eb2015c3c2ada0830","value":"100%"}},"03ba6fa0421f4d43a0e92daba919c42d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_00b5ca1b88944391aa4de1df616de5a3","max":1290,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17968df9d89c408ca0c615401a182c34","value":1290}},"8db91486c8344465ae8aff9a403a4d3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dbc5f98cdf44a71a3cabaff8dfbe058","placeholder":"​","style":"IPY_MODEL_49ab782c8c484b6aa181dbcbc2b05039","value":" 1290/1290 [21:24&lt;00:00,  1.78it/s]"}},"e04e8604244e43c3aea61a804f0bfaf9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edc75a93d1a64ecd80413f473be172e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0df3808ae44417eb2015c3c2ada0830":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00b5ca1b88944391aa4de1df616de5a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17968df9d89c408ca0c615401a182c34":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4dbc5f98cdf44a71a3cabaff8dfbe058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49ab782c8c484b6aa181dbcbc2b05039":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Installation & Setup"],"metadata":{"id":"ED0aB9gNXrid"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"GawjZPFAXeYL","executionInfo":{"status":"ok","timestamp":1701831881176,"user_tz":480,"elapsed":10780,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"outputs":[],"source":["#this cell only needs to be run once for every new run time\n","# Deleted a few things from code from Cynthia\n","!pip install transformers[torch,sentencepiece] torch datasets -U --quiet"]},{"cell_type":"code","source":["# Deleted a few things from prior code\n","\n","#important relevant modeling libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","# Code copied from Cynthia\n","from datasets import Dataset\n","\n","# Code copied from https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt.\n","import transformers\n","\n","from transformers import AutoModel, AutoTokenizer, AddedToken\n","# Code copied from: https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt and https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n","\n","# Copied from https://huggingface.co/learn/nlp-course/chapter3/4?fw=pt\n","from tqdm.auto import tqdm"],"metadata":{"id":"TFe7uUYBYgjT","executionInfo":{"status":"ok","timestamp":1701831889433,"user_tz":480,"elapsed":8260,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#copy this block over for all successive model iterations\n","import pandas as pd\n","import os\n","import json\n","import numpy as np\n","import ast\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.utils import resample\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OagJgPSujJ2x","executionInfo":{"status":"ok","timestamp":1701831891518,"user_tz":480,"elapsed":2090,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"e43c2bd0-f7d7-4888-d000-a7e7294b3fe1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Code may copy from lesson_4_BERT.ipynb\n","\n","model_name = \"bert-base-uncased\"\n","bert_model = AutoModel.from_pretrained(model_name)\n","bert_tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"id":"tEiG2h3Q1jDj","executionInfo":{"status":"ok","timestamp":1701831894436,"user_tz":480,"elapsed":2921,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Data processing for model specifically"],"metadata":{"id":"erUSt-8OtFdH"}},{"cell_type":"code","source":["# Changing max length to 512 as 512 is the maximium for BERT (copied from: https://huggingface.co/learn/nlp-course/)\n","max_length = 512"],"metadata":{"id":"QH7KfCoXKnHV","executionInfo":{"status":"ok","timestamp":1701831894437,"user_tz":480,"elapsed":6,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# # Function to pad or truncate the key_timing data\n","# def pad_or_truncate(array):\n","#     if len(array) < max_length:\n","#         # If the array is shorter than the desired length, pad it with zeros.\n","#         # You can use np.pad to add zeros at the end of the array.\n","#         return np.pad(array, (0, max_length - len(array)), 'constant', constant_values=(0.0))\n","#     else:\n","#         # If the array is longer than the desired length, truncate it.\n","#         # You can use array slicing to keep only the first 'desired_length' elements.\n","#         return array[:max_length]\n","\n","# # FUnction to ONLY truncate the key_timing data\n","# def truncate(array):\n","#   if len(array) < max_length:\n","#     return array\n","#   else:\n","#     return array[:max_length]\n","\n","\n","# # Function to convert a string to a Python list\n","# def string_to_list(input_string):\n","#     return ast.literal_eval(input_string)"],"metadata":{"id":"t9caK2cajYMp","executionInfo":{"status":"ok","timestamp":1701831894437,"user_tz":480,"elapsed":5,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Function to pad or truncate the key_timing data\n","def pad_or_truncate(array):\n","    if len(array) < max_length:\n","        # If the array is shorter than the desired length, pad it with zeros.\n","        # You can use np.pad to add zeros at the end of the array.\n","        return np.pad(array, (0, max_length - len(array)), 'constant', constant_values=(0.0))\n","    else:\n","        # If the array is longer than the desired length, truncate it.\n","        # You can use array slicing to keep only the first 'desired_length' elements.\n","        return array[:max_length]\n","\n","# Function to convert a string to a Python list\n","def string_to_list(input_string):\n","    return ast.literal_eval(input_string)\n","\n","# Convert object dtype to lists of floats using custom parsing\n","def custom_parse_string_to_list(input_string):\n","    # Remove brackets and split by ', ' to get individual values\n","    values = input_string.strip('[]').split(', ')\n","\n","    # Convert values to floats (handling 'nan' string separately)\n","    result = [float(val) if val != 'nan' else 0 for val in values]\n","\n","    return result"],"metadata":{"id":"dGIE2WOhnFoj","executionInfo":{"status":"ok","timestamp":1701831894437,"user_tz":480,"elapsed":5,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["######################## READ IN DATA ###################################################################################################\n","data_path = '/content/drive/My Drive/266 Assignments/266 Final Project'\n","files = os.listdir(data_path)\n","files = [x for x in files if '.csv' in x]\n","\n","filt_df = pd.read_csv(os.path.join(data_path, files[files.index('cleaned_data_with_ft.csv')]))\n","\n","#do some data cleanup to ensure timing sequence is in right data format\n","# filt_df['flight_time'] = filt_df['flight_time'].apply(string_to_list)\n","# Apply the custom parsing function to convert string to list of floats\n","filt_df['flight_time'] = filt_df['flight_time'].apply(custom_parse_string_to_list)\n","filt_df['flight_time'] = filt_df['flight_time'].apply(pad_or_truncate)"],"metadata":{"id":"PbxbeKbHjJs1","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":599,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["######################## IMPORT SPECIAL TOKENS ############################################################################################\n","json_file = os.path.join(data_path, \"token_map.json\")\n","with open(json_file, 'r') as json_file:\n","    charbert_token_map = json.load(json_file)\n","\n","added_tokens = [AddedToken(token) for token in charbert_token_map.values()]\n","# added_tokens"],"metadata":{"id":"GWwj2CC310To","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":6,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Add the special tokens from charbert_token_map to the tokenizer's vocabulary\n","# Looks like [unused1] to [unused26] are present for \"bert-base-uncased\" too: https://huggingface.co/bert-base-uncased/blob/main/vocab.txt\n","bert_tokenizer.add_tokens(added_tokens)"],"metadata":{"id":"ufzgWBnsmPMH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":6,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"62528c89-a6b5-4ada-ccc7-985009c46fc8"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# must also add special tokens to the model\n","bert_model.resize_token_embeddings(len(bert_tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7avUkhR1E5i","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":5,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"bc19b6a6-369c-4416-a767-ebf840eb9af3"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(30522, 768, padding_idx=0)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#resample the data to balance it exactly 50-50 HC-PD\n","\n","#separate the classes\n","class_1 = filt_df[filt_df['diagnosis'] == 1]\n","class_0 = filt_df[filt_df['diagnosis'] == 0]\n","\n","#downsample the majority class\n","class_0_down = resample(class_0, replace=False, n_samples = len(class_1), random_state=42)\n","\n","# Combine minority class with downsampled majority class\n","balanced_data = pd.concat([class_1, class_0_down])\n","len(balanced_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFBXHMgJRAt3","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":4,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"416ba3e8-8406-46d2-8068-6d67e64549e0"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2940"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#split the data\n","# Split the data into training, validation, and test sets\n","X = balanced_data[['response_content', 'flight_time']]\n","y = balanced_data['diagnosis']\n","\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"],"metadata":{"id":"RveqvyXiaWAF","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":4,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Put data into a pandas dataframe to then load into a hugging face dataset object\n","# Code and idea copied from https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html\n","train_df = X_train\n","train_df['labels']=y_train\n","train_df.columns = ['response', 'flight_time','labels']\n","\n","# Code copied from above\n","# Made a df of our validation data\n","val_df = X_val\n","val_df['labels']=y_val\n","val_df.columns = ['response', 'flight_time','labels']\n","\n","test_df = X_test\n","test_df['labels']=y_test\n","test_df.columns = ['response', 'flight_time','labels']"],"metadata":{"id":"YVSHsGxnsccc","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":3,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Code copied from https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html\n","# Make a hugging face dataset object from the pandas df we just made\n","train_dataset = Dataset.from_pandas(train_df)\n","\n","# Code copied from above\n","# Make a validation Dataset\n","val_dataset = Dataset.from_pandas(val_df)\n","\n","# Code copied from above\n","# Make a test Dataset\n","test_dataset = Dataset.from_pandas(test_df)"],"metadata":{"id":"vfJr5PJ3scU8","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":3,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Code copied from https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt and prior code above (likely from BERT lesson notebooks/assignment)\n","# Code also copied from https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt\n","# Create a tokenize function we'll use to tokenize the key sequences in the dataset\n","def tokenize_func(a):\n","  return bert_tokenizer(\n","    a['response'],\n","    # Changing padding to max_length, copied from https://huggingface.co/learn/nlp-course/chapter2/6?fw=pt\n","    # Getting rid of padding here (copying from https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt).\n","    # It's more efficient to do padding at the batch level later on (use \"dynamic padding\") according to the above source\n","    padding='max_length',\n","    # Trunction true should truncate to max length: Copied from https://huggingface.co/docs/transformers/main_classes/tokenizer\n","    truncation=True,\n","    # Testing a shorter max length based on https://huggingface.co/learn/nlp-course/chapter2/5?fw=pt\n","    # Getting rid of max length from here to, copying from: https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt\n","    # Reinstating max length since got an error\n","    max_length=max_length,\n","    # Getting rid of return tensors so that this code runs! Gave an erron when it was here\n","    # return_tensors='pt'\n","    )"],"metadata":{"id":"8gZO3xKzscLX","executionInfo":{"status":"ok","timestamp":1701831895033,"user_tz":480,"elapsed":3,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Code copied from https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt\n","# Tokenize the key sequences which will add the results to the dataset\n","tokenized_train_dataset = train_dataset.map(tokenize_func, batched=True)\n","\n","# Code copied from above\n","# Tokenize validation dataset\n","tokenized_val_dataset = val_dataset.map(tokenize_func, batched=True)\n","\n","# Code copied from above\n","# Tokenize test dataset\n","tokenized_test_dataset = test_dataset.map(tokenize_func, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cbcb322d3ac9442391d823e19dfc69f2","ffa651b1ab2d459dbbcd87642e40d9a1","6b823a70104d4a05ae896180be1ecec5","5a44d112e0b64954af40cdd54490fe56","5298d2abcf3145cd97b6fa11db0b1fdb","16a1a4cf7573468fb83f9ff6bf31b4a0","39c57964fc93457f889f9cee04512fef","24e500643f864fc9a9097e462d027987","7543df20c5674102b6d54887931ee237","8527295917704cd6be470a788ecd600e","b684fc4c32a44f1cb3f51d6a6211a658","3a0f137069244b8eadae6d71e2e611bf","7452c440c0ed4f00885ef525f1a5fa38","c9b618c5eb7048718e121b77e549f11a","dd4f7c8e50354fe091c1528d8253cbed","a7f6d334746744c5a488fbc8c943664f","58836e57c454442185ab99cf949245cf","2e730349d54a4de0afd590fa4861acc4","759f30cd97fe4e5895b7317d1bed090d","1de88949d8134dff899257ee12833ce2","c786831ca79d414998dd3e41388ee765","d6e4863a49cd4f788558e904433128bb","ffef0c4258cd49dc9f2ee89068b91626","80bcb22e490f4254a78abd92671cbfd1","156f0bf56cba44d28b8f69e27e929e16","fa939afabea5410587828d4bbe6869c6","5dd553c843474e0eb4fcf4284746c527","d45b25c2131b45658c367e071d282583","71718265694841049afad204d993f668","0ae4f33de90049daa36972ea1d392ff4","6d90b6a32bf44067a024752a3dd08bf3","9b7c82f2f53944609c642d901c9686b6","7280e075b86e4e5ba7499355c9306df9"]},"id":"vQj8gz9s3PKw","executionInfo":{"status":"ok","timestamp":1701831896636,"user_tz":480,"elapsed":1606,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"5f06fdad-9c21-485f-c4b3-84e22f020c7b"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2058 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbcb322d3ac9442391d823e19dfc69f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/441 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0f137069244b8eadae6d71e2e611bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/441 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffef0c4258cd49dc9f2ee89068b91626"}},"metadata":{}}]},{"cell_type":"code","source":["# Copied from https://huggingface.co/learn/nlp-course/chapter3/4?fw=pt\n","# Get rid of all columns in our dataset that our model won't accept\n","tokenized_train_dataset = tokenized_train_dataset.remove_columns(['response', '__index_level_0__',])\n","tokenized_val_dataset = tokenized_val_dataset.remove_columns(['response', '__index_level_0__',])\n","tokenized_test_dataset = tokenized_test_dataset.remove_columns(['response', '__index_level_0__',])"],"metadata":{"id":"zirRNqRYv9tE","executionInfo":{"status":"ok","timestamp":1701831897157,"user_tz":480,"elapsed":523,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Copied from https://huggingface.co/learn/nlp-course/chapter3/4?fw=pt\n","# Set output to PyTorch tensors\n","tokenized_train_dataset.set_format(\"torch\")\n","tokenized_val_dataset.set_format(\"torch\")\n","tokenized_test_dataset.set_format(\"torch\")"],"metadata":{"id":"apzurYSp2wAL","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Copied from https://huggingface.co/learn/nlp-course/chapter3/4?fw=pt\n","# Check column names align with what model expects\n","tokenized_train_dataset.column_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ScNzZpr41h6G","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"e88a3489-d2a7-4dcb-fcb3-def4494330c3"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['flight_time', 'labels', 'input_ids', 'token_type_ids', 'attention_mask']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Code copied from https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt\n","  # Copied from https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt:\n","  # \"... apply the correct amount of padding to the items of the dataset we want to batch together.\n","  # ... such a function via DataCollatorWithPadding. It takes a tokenizer when you instantiate it\n","   #(to know which padding token to use, and whether the model expects padding to be on the left or on the right of the inputs)\n","# Setting max length, and padding - copied from https://huggingface.co/docs/transformers/main_classes/data_collator\n","# Errored out, so got rid of these\n","data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"],"metadata":{"id":"Kq_6Fb6T3hqu","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":8,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#make data loaders\n","batch_size = 8\n","\n","\n","train_dataloader = DataLoader(tokenized_train_dataset, shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n","val_dataloader = DataLoader(tokenized_val_dataset, shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n","test_dataloader = DataLoader(tokenized_test_dataset, shuffle=True, batch_size=batch_size, collate_fn=data_collator)"],"metadata":{"id":"JUxs-3WWpaYC","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":8,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Check of Dataloader copied from https://huggingface.co/learn/nlp-course/chapter3/4?fw=pt\n","for batch in train_dataloader:\n","    break\n","{k: v.shape for k, v in batch.items()}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NnE4Myis30Qb","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":8,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"2a8d335e-f8d4-4776-c679-a56bb3fc98d7"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'flight_time': torch.Size([8, 512]),\n"," 'labels': torch.Size([8]),\n"," 'input_ids': torch.Size([8, 512]),\n"," 'token_type_ids': torch.Size([8, 512]),\n"," 'attention_mask': torch.Size([8, 512])}"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# BERT Model + LSTM WITH Key Timings"],"metadata":{"id":"nLHAWtFV_Yvj"}},{"cell_type":"code","source":["# Additional features input size\n","additional_features_size = max_length #last dimension of combined features tensor"],"metadata":{"id":"Th8y4b-lmzv7","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":6,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Code copied from above with architecture changed\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, bert_model, additional_features_size, num_labels=2):\n","        super(CustomModel, self).__init__()\n","        self.bert_model = bert_model\n","        self.additional_features_size = additional_features_size\n","\n","        # Add LSTM layers for additional features\n","        self.lstm1 = nn.LSTM(input_size=(768+additional_features_size), hidden_size=512, batch_first=True)\n","        # self.lstm2 = nn.LSTM(input_size=512, hidden_size=256, batch_first=True)\n","        # self.lstm3 = nn.LSTM(input_size=256, hidden_size=128, batch_first=True)\n","        # self.lstm4 = nn.LSTM(input_size=128, hidden_size=64, batch_first=True)\n","        # self.lstm5 = nn.LSTM(input_size=(64+additional_features_size), hidden_size=32, batch_first=True)\n","\n","        # Output layer for binary classification\n","        self.classifier = nn.Linear(512, num_labels)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids, flight_time):\n","        # BERT forward pass\n","        bert_outputs = self.bert_model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n","        bert_cls = bert_outputs[0][:,0,:] # Copying from above (see corresponding sources), getting the CLS token\n","\n","        # # LSTM forward pass for additional features\n","        # lstm_outputs1, _ = self.lstm1(bert_cls)\n","        # lstm_outputs2, _ = self.lstm2(lstm_outputs1)\n","        # lstm_outputs3, _ = self.lstm3(lstm_outputs2)\n","        # lstm_outputs4, _ = self.lstm4(lstm_outputs3)\n","\n","        # Concatenate BERT CLS and LSTM outputs\n","        combined_features = torch.cat((bert_cls, flight_time), dim=1)\n","\n","        lstm_outputs1, _ = self.lstm1(combined_features)\n","\n","        # Classification layer\n","        logits = self.classifier(lstm_outputs1)\n","\n","        return logits"],"metadata":{"id":"dSF8ALK41veW","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":6,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# class CustomModel(nn.Module):\n","#     def __init__(self, bert_model, additional_features_size, num_labels=2):\n","#         super(CustomModel, self).__init__()\n","#         self.bert_model = bert_model\n","#         self.additional_features_size = additional_features_size\n","\n","#         # Add LSTM layers for additional features\n","#         self.lstm1 = nn.LSTM(input_size=additional_features_size, hidden_size=64, batch_first=True)\n","#         self.lstm2 = nn.LSTM(input_size=64, hidden_size=32, batch_first=True)\n","#         self.lstm3 = nn.LSTM(input_size=32, hidden_size=16, batch_first=True)\n","\n","\n","#         # Output layer for binary classification\n","#         self.classifier = nn.Linear(16, num_labels)  # 768 is the size of the CharBERT embeddings\n","\n","#     def forward(self, input_ids, attention_mask):\n","#         # BERT forward pass\n","#         bert_outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n","#         # print(len(charbert_outputs))\n","#         bert_embeddings = bert_outputs[0][:,0,:] # Copying from above (see corresponding sources), getting the CLS token\n","\n","#         # # Concatenate BERT cls and time sequence\n","#         # combined_features = torch.cat((bert_embeddings, time_seq), dim=1)\n","\n","#         # print(f\"combined features: {combined_features.shape}\")\n","\n","#         print(f\"bert embedding: {bert_embeddings.shape}\")\n","#         # print(f\"time seq: {time_seq.shape}\")\n","\n","#         # LSTM forward pass for additional features\n","#         lstm_outputs1, _ = self.lstm1(bert_embeddings)\n","#         lstm_outputs2, _ = self.lstm2(lstm_outputs1)\n","#         lstm_outputs3, _ = self.lstm3(lstm_outputs2)\n","#         # last_lstm_output = lstm_outputs[:, -1, :].unsqueeze(1)\n","\n","\n","#         # # Concatenate BERT cls and time sequence\n","#         # combined_features = torch.cat((bert_embeddings, lstm_outputs3), dim=1)\n","\n","#         print(f\"output of last LSTM: {lstm_outputs3.shape}\")\n","\n","#         # Classification layer\n","#         logits = self.classifier(lstm_outputs3)\n","\n","#         print(f\"logits: {logits.shape}\")\n","\n","#         return logits"],"metadata":{"id":"M2PDduM6_ani","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":6,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# Instantiate the custom model\n","model = CustomModel(bert_model, additional_features_size)"],"metadata":{"id":"YjKYusfYAZwI","executionInfo":{"status":"ok","timestamp":1701831897158,"user_tz":480,"elapsed":6,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Copied from https://huggingface.co/learn/nlp-course/chapter3/4?fw=pt\n","# Set up to use the GPU\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCbJpT_V12nY","executionInfo":{"status":"ok","timestamp":1701831903512,"user_tz":480,"elapsed":6358,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"a96350f5-5030-4d12-bc3a-3243fa019c8c"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["## Train the model"],"metadata":{"id":"MHg9k9zH_1FE"}},{"cell_type":"code","source":["# Define helper functions to calculate accuracy\n","# Code and comments copied from https://medium.com/p/a70372764432\n","\n","def get_accuracy(model, dataloader):\n","  '''puts model in evaluation mode then gets accuracy'''\n","  model = model.eval()\n","  correct = 0\n","  total_examples = 0\n","  for i, batch in enumerate(dataloader):\n","    with torch.no_grad():\n","      logits = model(input_ids = batch['input_ids'].to(device), # Copying from https://discuss.pytorch.org/t/expected-all-tensors-to-be-on-the-same-device-but-found-at-least-two-devices-cuda-0-and-cpu/98537/2, putting input data to the same device as the model\n","        attention_mask = batch['attention_mask'].to(device),\n","        token_type_ids = batch['token_type_ids'].to(device),\n","        flight_time = batch['flight_time'].to(device)\n","        )\n","    predictions =  torch.argmax(logits, dim=1) # Copied from https://pytorch.org/docs/stable/generated/torch.argmax.html\n","    labels = batch['labels'].to(device)\n","    labels = labels.view(predictions.shape)\n","    comparison = labels == predictions\n","    correct += torch.sum(comparison)\n","    total_examples += len(comparison)\n","\n","  return correct / total_examples"],"metadata":{"id":"tUWpYRHe13d5","executionInfo":{"status":"ok","timestamp":1701831903512,"user_tz":480,"elapsed":15,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["num_epochs = 5"],"metadata":{"id":"CnfHkoq-13Z2","executionInfo":{"status":"ok","timestamp":1701831903512,"user_tz":480,"elapsed":14,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Code copied from Cynthia\n","learning_rate=2e-5\n","#Define Loss Function and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"7IA8CITE13Vn","executionInfo":{"status":"ok","timestamp":1701831903512,"user_tz":480,"elapsed":14,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# Code copied from Cynthia\n","# Lists to store training and validation losses and accuracies\n","train_losses = []\n","val_losses = []\n","val_accuracies = []"],"metadata":{"id":"WK1AjGD019BV","executionInfo":{"status":"ok","timestamp":1701831903512,"user_tz":480,"elapsed":14,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Copied from https://huggingface.co/learn/nlp-course/chapter3/4?fw=pt\n","# Set up to get a progress bar\n","num_train_steps = num_epochs*len(train_dataloader)"],"metadata":{"id":"jR7BegGc181q","executionInfo":{"status":"ok","timestamp":1701831903512,"user_tz":480,"elapsed":14,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Code copied from Cynthia\n","# Changes I've made may copy from throughout this course: https://huggingface.co/learn/nlp-course**\n","# May also copy from lesson_4_BERT.ipynb\n","# Training loop\n","\n","progress_bar = tqdm(range(num_train_steps))\n","\n","for epoch in range(num_epochs):\n","    model = model.train()\n","    train_loss = 0.0\n","    val_loss = 0.0\n","    # Training loop\n","    for batch in train_dataloader:\n","\n","        input_ids = batch['input_ids'].to(device) # Copying from https://discuss.pytorch.org/t/expected-all-tensors-to-be-on-the-same-device-but-found-at-least-two-devices-cuda-0-and-cpu/98537/2, putting input data to the same device as the model\n","        attention_mask = batch['attention_mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        flight_time = batch['flight_time'].to(device)\n","\n","        outputs = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, flight_time=flight_time)\n","\n","        loss = criterion(outputs, batch[\"labels\"].to(device))\n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        train_loss += loss.item()\n","\n","        progress_bar.update(1)\n","\n","    avg_train_loss = train_loss / len(train_dataloader)\n","    train_losses.append(avg_train_loss)\n","\n","    train_accuracy = get_accuracy(model,train_dataloader)\n","    val_accuracy = get_accuracy(model,val_dataloader)\n","\n","    # Code copies from https://medium.com/p/a70372764432 and above (see corresponding sources)\n","    # Evaluation loop to get validation loss\n","    model = model.eval()\n","    for batch in val_dataloader:\n","\n","        input_ids = batch['input_ids'].to(device) # Copying from https://discuss.pytorch.org/t/expected-all-tensors-to-be-on-the-same-device-but-found-at-least-two-devices-cuda-0-and-cpu/98537/2, putting input data to the same device as the model\n","        attention_mask = batch['attention_mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        flight_time = batch['flight_time'].to(device)\n","\n","        with torch.no_grad():\n","          outputs = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, flight_time=flight_time)\n","          loss = criterion(outputs, batch[\"labels\"].to(device))\n","          val_loss += loss.item()\n","\n","    avg_val_loss = val_loss / len(val_dataloader)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss: {avg_train_loss:.4f}  Train Accuracy: {train_accuracy:.4f}  Val Loss: {avg_val_loss:.4f}  Val Accuracy: {val_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["bb96595386d24ff8a666edd26fce2657","4ca3ebe8b9a146929a7f060dde3ac69a","03ba6fa0421f4d43a0e92daba919c42d","8db91486c8344465ae8aff9a403a4d3d","e04e8604244e43c3aea61a804f0bfaf9","edc75a93d1a64ecd80413f473be172e1","a0df3808ae44417eb2015c3c2ada0830","00b5ca1b88944391aa4de1df616de5a3","17968df9d89c408ca0c615401a182c34","4dbc5f98cdf44a71a3cabaff8dfbe058","49ab782c8c484b6aa181dbcbc2b05039"]},"id":"ijCs4EZR2AhN","outputId":"26305bbd-11c8-4c61-bbb0-db89a6786e05","executionInfo":{"status":"ok","timestamp":1701833280093,"user_tz":480,"elapsed":1376595,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1290 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb96595386d24ff8a666edd26fce2657"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/5: Train Loss: 0.6654  Train Accuracy: 0.6482  Val Loss: 0.6268  Val Accuracy: 0.6145\n","Epoch 2/5: Train Loss: 0.6139  Train Accuracy: 0.6672  Val Loss: 0.5918  Val Accuracy: 0.6553\n","Epoch 3/5: Train Loss: 0.5842  Train Accuracy: 0.6846  Val Loss: 0.5822  Val Accuracy: 0.6576\n","Epoch 4/5: Train Loss: 0.5681  Train Accuracy: 0.6963  Val Loss: 0.5725  Val Accuracy: 0.7052\n","Epoch 5/5: Train Loss: 0.5538  Train Accuracy: 0.7318  Val Loss: 0.5727  Val Accuracy: 0.6961\n"]}]},{"cell_type":"code","source":["#modified get predictions function\n","def get_predictions(model, dataloader):\n","    model = model.eval()\n","    predictions_list = []\n","    true_labels_list = []\n","\n","    for batch in dataloader:\n","        with torch.inference_mode():\n","            logits = model(input_ids=batch['input_ids'].to(device),\n","                           attention_mask=batch['attention_mask'].to(device),\n","                           token_type_ids=batch['token_type_ids'].to(device),\n","                           flight_time = batch['flight_time'].to(device))\n","\n","        predictions = torch.argmax(logits, dim=1)\n","        predictions = list(predictions.cpu().numpy())\n","        true_labels = list(batch['labels'].cpu().numpy())  # Replace 'labels' with your true labels key\n","\n","        predictions_list.extend(predictions)\n","        true_labels_list.extend(true_labels)\n","\n","    return predictions_list, true_labels_list"],"metadata":{"id":"1mDrTT9EtzIJ","executionInfo":{"status":"ok","timestamp":1701833280094,"user_tz":480,"elapsed":5,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Code copied from above (see corresponding sources)\n","# Get probs for AUC calculation\n","def get_probs(model, dataloader):\n","    model = model.eval()\n","    probs_list = []\n","    true_labels_list = []\n","\n","    for batch in dataloader:\n","        with torch.inference_mode():\n","            logits = model(input_ids=batch['input_ids'].to(device),\n","                           attention_mask=batch['attention_mask'].to(device),\n","                           token_type_ids=batch['token_type_ids'].to(device),\n","                           flight_time = batch['flight_time'].to(device))\n","\n","        softmax = nn.Softmax(dim=1) # Copied from https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\n","        probs = softmax(logits)\n","\n","        probs = list(probs.cpu().numpy())\n","\n","        true_labels = list(batch['labels'].cpu().numpy())  # Replace 'labels' with your true labels key\n","\n","        for prob in probs:\n","          probs_list.append(prob[1])\n","        true_labels_list.extend(true_labels)\n","\n","    return probs_list, true_labels_list\n"],"metadata":{"id":"4M5DFUmUNTmq","executionInfo":{"status":"ok","timestamp":1701833280094,"user_tz":480,"elapsed":4,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# # Get predictions\n","# # Code copied from https://docs.databricks.com/en/machine-learning/model-inference/resnet-model-inference-pytorch.html\n","# # and https://medium.com/p/a70372764432\n","# # and from above (see corresponding sources)\n","\n","# def get_predictions(model, dataloader):\n","#   '''gets predictions from a model'''\n","#   model = model.eval()\n","#   predictions_list = []\n","#   for batch in dataloader:\n","#     with torch.inference_mode():\n","#       logits = model(input_ids = batch['input_ids'].to(device), # Copying from https://discuss.pytorch.org/t/expected-all-tensors-to-be-on-the-same-device-but-found-at-least-two-devices-cuda-0-and-cpu/98537/2, putting input data to the same device as the model\n","#         attention_mask = batch['attention_mask'].to(device),\n","#         token_type_ids = batch['token_type_ids'].to(device),\n","#         time_seq = batch['time_seq'].to(device)\n","#         )\n","#     predictions = torch.argmax(logits, dim=1) # Copied from https://pytorch.org/docs/stable/generated/torch.argmax.html\n","#     predictions = list(predictions.cpu().numpy())\n","#     for prediction in predictions:\n","#       predictions_list.append(prediction)\n","\n","#   return predictions_list"],"metadata":{"id":"ipxOTtTC2G5_","executionInfo":{"status":"ok","timestamp":1701833280094,"user_tz":480,"elapsed":3,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["bert_lstm_val_predictions, true_val_labels = get_predictions(model, val_dataloader)"],"metadata":{"id":"u2esKlvB2G2W","executionInfo":{"status":"ok","timestamp":1701833293915,"user_tz":480,"elapsed":13824,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# Now let's evaluate the model (code copied from prior notebook)\n","\n","accuracy_val = accuracy_score(np.array(true_val_labels), np.array(bert_lstm_val_predictions))\n","precision_val = precision_score(np.array(true_val_labels), np.array(bert_lstm_val_predictions))\n","recall_val = recall_score(np.array(true_val_labels), np.array(bert_lstm_val_predictions))\n","f1_val = f1_score(np.array(true_val_labels), np.array(bert_lstm_val_predictions))\n","\n","print(\"Accuracy: \", accuracy_val)\n","print(\"Precision: \", precision_val)\n","print(\"Recall: \", recall_val)\n","print(\"F1-Score: \", f1_val)"],"metadata":{"id":"Gt63IrIA2Gye","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701833293915,"user_tz":480,"elapsed":3,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"ef2fae7f-f8d3-453a-9fdc-b7c70e59c33e"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.7120181405895691\n","Precision:  0.9468085106382979\n","Recall:  0.4218009478672986\n","F1-Score:  0.5836065573770493\n"]}]},{"cell_type":"code","source":["bert_lstm_test_predictions, true_test_labels = get_predictions(model, test_dataloader)"],"metadata":{"id":"30g0VRrt2GtO","executionInfo":{"status":"ok","timestamp":1701833307713,"user_tz":480,"elapsed":13800,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["bert_lstm_test_probs, true_test_labels_for_probs = get_probs(model, test_dataloader)"],"metadata":{"id":"lND405PYNXy7","executionInfo":{"status":"ok","timestamp":1701833321688,"user_tz":480,"elapsed":13978,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["# Now let's evaluate the model (code copied from prior notebook)\n","\n","accuracy_test = accuracy_score(np.array(true_test_labels), np.array(bert_lstm_test_predictions))\n","precision_test = precision_score(np.array(true_test_labels), np.array(bert_lstm_test_predictions))\n","recall_test = recall_score(np.array(true_test_labels), np.array(bert_lstm_test_predictions))\n","f1_test = f1_score(np.array(true_test_labels), np.array(bert_lstm_test_predictions))\n","auc_test = roc_auc_score(np.array(true_test_labels_for_probs), np.array(bert_lstm_test_probs))\n","\n","print(\"Accuracy: \", accuracy_test)\n","print(\"Precision: \", precision_test)\n","print(\"Recall: \", recall_test)\n","print(\"F1-Score: \", f1_test)\n","print(\"AUC: \", auc_test)"],"metadata":{"id":"eQVk8OcRBW6t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701833321688,"user_tz":480,"elapsed":21,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"2d7d22f1-73a7-4dfe-b71a-6f245fedd8d7"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  0.655328798185941\n","Precision:  0.9029126213592233\n","Recall:  0.39574468085106385\n","F1-Score:  0.5502958579881657\n","AUC:  0.8443709977277423\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","\n","name = \"BERT-LSTM on words & flight time\"\n","# Compute confusion matrix\n","cm = confusion_matrix(true_test_labels, bert_lstm_test_predictions)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(8, 6))\n","plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.title(name)\n","plt.colorbar()\n","\n","classes = ['HC', 'PD']  # Change these labels according to your classes\n","tick_marks = np.arange(len(classes))\n","plt.xticks(tick_marks, classes)\n","plt.yticks(tick_marks, classes)\n","\n","thresh = cm.max() / 2.\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        plt.text(j, i, format(cm[i, j], 'd'),\n","                 horizontalalignment=\"center\",\n","                 color=\"black\" if cm[i, j] > thresh else \"black\")\n","\n","plt.ylabel('True label')\n","plt.xlabel('Predicted label')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"F18CADLBCBmM","colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"status":"ok","timestamp":1701833321688,"user_tz":480,"elapsed":19,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"756ab9fc-3d7a-4d19-baf7-c4b8288ffcfe"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x600 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["#save the confusion matrix\n","\n","file_name = f\"confusion_matrix_{name}.png\"\n","plt.savefig(os.path.join(data_path, file_name))"],"metadata":{"id":"pf_GMvQAVaai","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1701833321688,"user_tz":480,"elapsed":5,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}},"outputId":"5a3b5613-1e4d-411e-8870-38e4a3119d11"},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","source":["import csv\n","from datetime import datetime\n","\n","def write_metrics_to_csv(filename, metrics):\n","    try:\n","        with open(filename, 'a', newline='') as file:\n","            writer = csv.DictWriter(file, fieldnames=metrics.keys())\n","            if file.tell() == 0:\n","              writer.writeheader()  # Write header if the file is empty\n","\n","            writer.writerow(metrics)\n","    except IOError:\n","        print(\"Error writing to file\")\n","\n","timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","\n","metrics = {\n","    \"model name\": name,\n","    \"timestamp\": timestamp,\n","    \"accuracy\": accuracy_test,\n","    \"precision\": precision_test,\n","    \"recall\": recall_test,\n","    \"f1\": f1_test,\n","    \"auc\": auc_test\n","}\n","\n","# Write the metrics to a CSV file\n","write_metrics_to_csv(os.path.join(data_path, \"metrics.csv\"), metrics)"],"metadata":{"id":"wzY5-LY0t-eA","executionInfo":{"status":"ok","timestamp":1701833321689,"user_tz":480,"elapsed":5,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# args = TrainingArguments(\n","#     \"test-trainer\",\n","#     evaluation_strategy = \"epoch\",\n","#     save_strategy = \"epoch\",\n","#     learning_rate=2e-5,\n","#     per_device_train_batch_size=batch_size,\n","#     per_device_eval_batch_size=batch_size,\n","#     num_train_epochs=5,\n","#     weight_decay=0.01,\n","#     load_best_model_at_end=False,\n","#     metric_for_best_model='f1',\n","# )"],"metadata":{"id":"6PeTwNY1Ba3B","executionInfo":{"status":"ok","timestamp":1701833321689,"user_tz":480,"elapsed":5,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# # Copied from https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt\n","# trainer = Trainer(\n","#     model,\n","#     args,\n","#     train_dataset=tokenized_train_dataset,\n","#     eval_dataset=tokenized_val_dataset,\n","#     data_collator=data_collator,\n","#     tokenizer=charbert_tokenizer\n","# )"],"metadata":{"id":"5VTsynxaBawe","executionInfo":{"status":"ok","timestamp":1701833322131,"user_tz":480,"elapsed":447,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z2ljpB7YBarw","executionInfo":{"status":"ok","timestamp":1701833322131,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# num_epochs = 5"],"metadata":{"id":"NPWB0f60_01j","executionInfo":{"status":"ok","timestamp":1701833322131,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# learning_rate=2e-5\n","# #Define Loss Function and Optimizer\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"PhtLNDfY_6ij","executionInfo":{"status":"ok","timestamp":1701833322131,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["# # Lists to store training and validation losses and accuracies\n","# train_losses = []\n","# val_losses = []\n","# val_accuracies = []\n","\n","# # Training loop\n","# for epoch in range(num_epochs):\n","#     train_loss = 0.0\n","\n","#     # Training loop\n","#     for batch in train_dataloader:\n","#         input_ids = batch['input_ids']\n","#         attention_mask = batch['attention_mask']\n","#         # token_type_ids = batch['token_type_ids']\n","\n","#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","#         loss = criterion(outputs, batch[\"labels\"])\n","#         loss.backward()\n","#         optimizer.step()\n","#         optimizer.zero_grad()\n","#         train_loss += loss.item()\n","\n","#     avg_train_loss = train_loss / len(train_dataloader)\n","#     train_losses.append(avg_train_loss)\n","\n","#     # Evaluate the model on the validation set\n","#     # results = trainer.evaluate(eval_dataset=val_dataloader)\n","#     # val_loss = results[\"eval_loss\"]\n","#     # val_accuracy = results[\"eval_accuracy\"]\n","#     # val_losses.append(val_loss)\n","#     # val_accuracies.append(val_accuracy)\n","\n","#     print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss: {avg_train_loss:.4f}\")"],"metadata":{"id":"oF9q438D_-QL","executionInfo":{"status":"ok","timestamp":1701833322131,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["# BERT Model + LSTM With Key Timings\n","Note on warning below: that ['classifier.bias', 'classifier.weight'] are newly initialized. From Jennifer's OH: The CharBert model we're using likely wasn't built to work with Hugging Face's loader. We're probably losing pre-training. Could try to load it in from git directly, but that will be difficult (3 year old repo) and we'd have to match their python version, etc. Can proceed with this as is, just be aware we're likely losing some (or all?) pre-training. Also skimmed: https://discuss.huggingface.co/t/is-some-weights-of-the-model-were-not-used-warning-normal-when-pre-trained-bert-only-by-mlm/5672"],"metadata":{"id":"6aJPGt_Xb_qp"}},{"cell_type":"code","source":["# class CustomModel(nn.Module):\n","#     def __init__(self, bert_model, additional_features_size, num_labels=2):\n","#         super(CustomModel, self).__init__()\n","#         self.bert_model = bert_model\n","#         self.additional_features_size = additional_features_size\n","\n","#         # Add LSTM layers for additional features\n","#         self.lstm1 = nn.LSTM(input_size=additional_features_size, hidden_size=64, batch_first=True)\n","#         self.lstm2 = nn.LSTM(input_size=64, hidden_size=32, batch_first=True)\n","#         self.lstm3 = nn.LSTM(input_size=32, hidden_size=16, batch_first=True)\n","\n","\n","#         # Output layer for binary classification\n","#         self.classifier = nn.Linear(16, num_labels)  # 768 is the size of the CharBERT embeddings\n","\n","#     def forward(self, input_ids, attention_mask, token_type_ids, time_seq):\n","#         # BERT forward pass\n","#         bert_outputs = self.bert_model(input_ids=input_ids, attention_mask=attention_mask)\n","#         # print(len(charbert_outputs))\n","#         bert_embeddings = bert_outputs[0][:,0,:] # Copying from above (see corresponding sources), getting the CLS token\n","\n","#         # Concatenate BERT cls and time sequence\n","#         combined_features = torch.cat((bert_embeddings, time_seq), dim=1)\n","\n","#         print(f\"combined features: {combined_features.shape}\")\n","\n","#         print(f\"bert embedding: {bert_embeddings.shape}\")\n","#         print(f\"time seq: {time_seq.shape}\")\n","\n","#         # LSTM forward pass for additional features\n","#         lstm_outputs1, _ = self.lstm1(combined_features)\n","#         lstm_outputs2, _ = self.lstm2(lstm_outputs1)\n","#         lstm_outputs3, _ = self.lstm3(lstm_outputs2)\n","#         # last_lstm_output = lstm_outputs[:, -1, :].unsqueeze(1)\n","\n","\n","#         # # Concatenate BERT cls and time sequence\n","#         # combined_features = torch.cat((bert_embeddings, lstm_outputs3), dim=1)\n","\n","#         print(f\"output of last LSTM: {lstm_outputs3.shape}\")\n","\n","#         # Classification layer\n","#         logits = self.classifier(lstm_outputs3)\n","\n","#         print(f\"logits: {logits.shape}\")\n","#         # #concatenate time_seq to last hidden state\n","#         # #do some reshaping of time_seq for concatenatino\n","#         # time_seq_dim = time_seq.unsqueeze(1).repeat(1, 322, 1)  # 16 x 322 x 512\n","#         # combined = torch.cat((charbert_embeddings, time_seq_dim), dim=-1)  # 16 x 322 x (768 + 512)\n","#         # # combined_features = torch.cat((charbert_embeddings, time_seq), dim=1)\n","\n","#         # print(f\"combined shape: {combined.shape}\")\n","#         # print(f\"embeddings shape: {charbert_embeddings.shape}\")\n","#         # print(f\"key timings shape: {time_seq_dim.shape}\")\n","\n","#         # # LSTM forward pass for additional features\n","#         # lstm_outputs1, _ = self.lstm1(combined)\n","#         # lstm_outputs2, _ = self.lstm2(lstm_outputs1)\n","#         # lstm_outputs3, _ = self.lstm3(lstm_outputs2)\n","#         # # last_lstm_output = lstm_outputs[:, -1, :].unsqueeze(1)\n","\n","\n","#         # print(f\"lstm output shape: {lstm_outputs3.shape}\")\n","\n","#         # #flatten the tensor before concatenation\n","#         # flattened_tensor = lstm_outputs3.reshape(lstm_outputs3.size(0), -1)\n","#         # print(f\"input shape into classification layer: {flattened_tensor.shape}\")\n","\n","\n","#         # # Classification layer\n","#         # logits = self.classifier(flattened_tensor)\n","\n","#         # print(f\"model output shape: {logits.shape}\")\n","#         # print(logits)\n","\n","#         # #take argmax to get most likely logit?\n","#         # pred_labels = np.argmax(logits, axis=-1)\n","#         # print(f\"model argmax output shape: {pred_labels.shape}\")\n","#         # print(pred_labels)\n","\n","#         return logits"],"metadata":{"id":"LPJ9mMwomvrc","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":10,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# # Instantiate the custom model\n","# model = CustomModel(bert_model, additional_features_size)"],"metadata":{"id":"Ch5mM-OZmvn-","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["## Train the model"],"metadata":{"id":"xgSfBO9ln91U"}},{"cell_type":"code","source":["# num_epochs = 5"],"metadata":{"id":"Kk3iUXUXtX6f","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["# learning_rate=2e-5\n","# #Define Loss Function and Optimizer\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"jvwlKAyx5sgz","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":9,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# # Lists to store training and validation losses and accuracies\n","# train_losses = []\n","# val_losses = []\n","# val_accuracies = []\n","\n","# # Training loop\n","# for epoch in range(num_epochs):\n","#     train_loss = 0.0\n","\n","#     # Training loop\n","#     for batch in train_dataloader:\n","#         input_ids = batch['input_ids']\n","#         attention_mask = batch['attention_mask']\n","#         token_type_ids = batch['token_type_ids']\n","#         time_seq = batch['time_seq']\n","\n","#         outputs = model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, time_seq=time_seq)\n","#         loss = criterion(outputs, batch[\"labels\"])\n","#         loss.backward()\n","#         optimizer.step()\n","#         optimizer.zero_grad()\n","#         train_loss += loss.item()\n","\n","#     avg_train_loss = train_loss / len(train_dataloader)\n","#     train_losses.append(avg_train_loss)\n","\n","#     # Evaluate the model on the validation set\n","#     # results = trainer.evaluate(eval_dataset=val_dataloader)\n","#     # val_loss = results[\"eval_loss\"]\n","#     # val_accuracy = results[\"eval_accuracy\"]\n","#     # val_losses.append(val_loss)\n","#     # val_accuracies.append(val_accuracy)\n","\n","#     print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss: {avg_train_loss:.4f}\")"],"metadata":{"id":"GKxMHKoW5xrs","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":8,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["# # You can save the trained model at the end of training\n","# trainer.save_model(\"./custom_model\")\n","\n","# # Evaluation on the test set\n","# results = trainer.evaluate(eval_dataset=test_dataloader)\n","# test_loss = results[\"eval_loss\"]\n","# test_accuracy = results[\"eval_accuracy\"]\n","\n","# print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2%}\")\n"],"metadata":{"id":"O7u77pqis6p9","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":8,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# # Get predictions from the model for the validation dataset\n","# # Code copied from https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt\n","# predictions = trainer.predict(tokenized_val_dataset)\n","# print(predictions.predictions.shape,predictions.label_ids.shape)"],"metadata":{"id":"5dhD3zc_tgpQ","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":8,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# import numpy as np\n","# # Copied from https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt\n","# # \"As you can see, predictions is a two-dimensional array with shape 408 x 2 (408 being the number of elements in the dataset we used).\n","# # Those are the logits for each element of the dataset we passed to predict() (as you saw in the previous chapter, all Transformer models return logits).\n","# # To transform them into predictions that we can compare to our labels, we need to take the index with the maximum value on the second axis\"\n","# # Code copied from https://huggingface.co/learn/nlp-course/chapter3/3?fw=pt\n","# charBert_pred_labels = np.argmax(predictions.predictions, axis=-1)"],"metadata":{"id":"WcSdKyxAtgku","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":7,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# # Now let's evaluate the model (code copied from above)\n","\n","# accuracy_charBERT = accuracy_score(np.array(y_val), charBert_pred_labels)\n","# precision_charBERT = precision_score(np.array(y_val), charBert_pred_labels)\n","# recall_charBERT = recall_score(np.array(y_val), charBert_pred_labels)\n","# f1_charBERT = f1_score(np.array(y_val), charBert_pred_labels)\n","\n","# print(\"Accuracy: \", accuracy_charBERT)\n","# print(\"Precision: \", precision_charBERT)\n","# print(\"Recall: \", recall_charBERT)\n","# print(\"F1-Score: \", f1_charBERT)"],"metadata":{"id":"OqNUXSUItgf4","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":7,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O80XugWS9rvB","executionInfo":{"status":"ok","timestamp":1701833322132,"user_tz":480,"elapsed":7,"user":{"displayName":"Cynthia Xu","userId":"04832706551111327404"}}},"execution_count":59,"outputs":[]}]}